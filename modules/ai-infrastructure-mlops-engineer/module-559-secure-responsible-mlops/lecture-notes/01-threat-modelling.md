# Lecture 01 · Threat Modelling for ML Systems

## Objectives
- Identify unique threat vectors for ML pipelines, model artefacts, and runtime services.
- Reuse security engineer threat modelling approaches while tailoring to data/model risk.
- Prioritize mitigations and track remediation in partnership with platform/security teams.

## Key Topics
1. **Adversarial Scenarios** — data poisoning, model theft, prompt injection, supply-chain compromise.
2. **Assets & Trust Boundaries** — datasets, feature stores, model registries, deployment endpoints.
3. **Mitigation Patterns** — access control, monitoring, anomaly detection, rollback strategies.
4. **Documentation & Evidence** — STRIDE-style analysis, risk scoring, remediation backlog.
5. **Collaboration** — integrating findings with governance (MOD-557) and incident response (MOD-558).

## Activities
- Populate a threat model using legacy security templates.
- Prioritize mitigation backlog with shared risk scoring rubric.
- Align remediation plan with governance board and production ops stakeholders.
