# Housekeeping â€” MOD-526 Distributed Inference & Scaling

- **Status:** Distributed inference manifests, batching scripts, and observability assets need to be migrated.
- **To-Do:**
  - Add sample deployment configs (TensorRT-LLM, vLLM, Ray Serve) with benchmarking data.
  - Document continuous batching/autoscaling policies and chaos test results.
  - Provide dashboards and incident response runbooks aligned with MLOps guidance.
