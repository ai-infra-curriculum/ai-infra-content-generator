# Role Research Brief: Senior AI Infrastructure Engineer

**Experience Level:** 5-8 years building and operating large-scale ML/AI infrastructure; typically leads technical initiatives and mentors mid-level engineers.  
**Market Demand:** High â€” organizations scaling LLM, generative AI, and real-time ML systems require senior operators who can balance reliability, cost, and velocity. Roles cluster in cloud providers, AI-native startups, finance, and enterprise platform teams.  
**Salary Range (US):**
- Min: $150,000
- Median: $205,000
- Max: $280,000

## Core Responsibilities
- Architect highly available, multi-region ML infrastructure spanning data, training, and serving layers.
- Lead design and implementation of distributed training platforms (Ray, Horovod, PyTorch DDP/FSDP).
- Build custom Kubernetes operators, controllers, and GitOps workflows for ML workloads.
- Optimize GPU utilization, inference performance, and cost across heterogeneous hardware.
- Establish observability, incident response, and SLO governance for AI production systems.
- Drive infrastructure security, compliance, and data governance posture for ML pipelines.
- Mentor junior and mid-level engineers; lead design reviews, architecture councils, and postmortems.
- Collaborate with research, data science, and product stakeholders to translate requirements into infrastructure roadmaps.
- Evaluate emerging tooling (vector databases, LLM serving frameworks, feature platforms) and guide adoption.

## Technical Skills
### Required
- Advanced Kubernetes (operators, CRDs, service mesh, multi-cluster management).
- Distributed training frameworks (Ray, Horovod, PyTorch DDP/FSDP) and high-performance networking.
- GPU platform expertise (CUDA, Nsight profiling, MIG/vGPU, TensorRT, performance tuning).
- Infrastructure as Code at scale (Terraform/Pulumi, policy as code, GitOps, platform APIs).
- Observability engineering (Prometheus, Grafana, OpenTelemetry, advanced alert design).
- Secure multi-cloud architecture, network design, and secrets/identity management.
- Programming proficiency in Python and Go (or Rust) for tooling, operators, and automation.
- Mature CI/CD, release governance, and environment promotion strategies.

### Preferred
- Experience deploying and optimizing LLM/RAG platforms with vLLM, TGI, TensorRT-LLM, or similar.
- Deep expertise with multi-region DR, chaos engineering, and cost optimization for GPU fleets.
- Familiarity with compliance frameworks (SOC 2, HIPAA, FedRAMP) for ML platforms.
- Contributions to open source infrastructure projects or published technical articles.
- Ability to lead cross-functional programs and influence executive stakeholders.

## Soft Skills & Leadership Expectations
- Strategic planning and roadmap ownership for AI infrastructure initiatives.
- Coaching, feedback delivery, and talent development for engineering teams.
- Clear written communication (architecture docs, ADRs, runbooks, postmortems).
- Stakeholder management with product, research, and security organizations.
- Decision making under ambiguity with focus on measurable impact and reliability.

## Hiring Signals
- Prior ownership of production ML/LLM platform launches with quantified improvements (latency, cost, uptime).
- Demonstrated success leading incident response and reliability programs.
- Track record of mentoring engineers and driving adoption of infrastructure best practices.
- Open source contributions or thought leadership in ML infrastructure domains.
