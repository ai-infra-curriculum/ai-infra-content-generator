# Role Research Brief: AI Infrastructure ML Platform Engineer

**Experience Level:** 8–12 years building distributed systems with 3–5 years focused on ML platform engineering (feature stores, workflow orchestration, model serving). Candidates often evolve from senior platform/SRE/ML engineers and require strong product-thinking and cross-functional collaboration skills.  
**Market Demand:** High at hyperscalers, AI-first startups, fintech, e-commerce, healthcare, and enterprises building internal ML platforms. Roles frequently span platform engineering, MLOps, and developer experience teams.  
**Salary Range (US 2025):**
- Min: $200,000
- Median: $260,000
- Max: $380,000+ (base); total compensation often exceeds $430k in top-tier companies.

## Core Responsibilities
- Design and operate self-service ML platforms covering experimentation, training, serving, and observability workflows.
- Build and scale feature stores, model registries, workflow orchestration, and serving gateways.
- Deliver developer experience tooling (CLI/SDK/UI) that accelerates adoption, governance, and quality.
- Implement multi-tenant resource governance, cost optimization, and reliability for platform services.
- Integrate security, compliance, and policy guardrails (policy-as-code, audit logging, RBAC) across pipelines.
- Partner with data engineering, product, research, and SRE teams to align platform roadmaps with business outcomes.
- Define SLAs/SLOs, observability dashboards, and incident response playbooks for platform services.
- Mentor platform engineers, contribute to hiring, and drive platform product mindset within the organization.

## Technical & Strategic Skills
### Required
- Strong distributed systems background (Kubernetes, service meshes, cloud infrastructure, microservices patterns).
- Proven experience with ML platform components: feature stores, workflow orchestration (Airflow, Kubeflow, Flyte, Dagster), model registry/promotion, inference platforms.
- Automation expertise (Terraform, Helm, CI/CD pipelines, GitOps) and infrastructure-as-code practices.
- Observability (Prometheus, Grafana, OpenTelemetry) and FinOps (cost dashboards, chargeback/showback).
- API/platform product design—versioning, documentation, developer onboarding, usage analytics.
- Data governance and compliance alignment (lineage, data contracts, auditability).
- Collaboration with security/compliance teams for guardrails, secrets management, and zero-trust integration.

### Preferred
- Experience with multi-cloud or hybrid deployments, workload portability, and edge serving.
- Familiarity with ML experimentation tooling (MLflow, Vertex AI, SageMaker, custom platforms).
- Exposure to policy-as-code tooling (OPA, Kyverno, Cloud Custodian) and platform governance frameworks.
- Product mindset: roadmap planning, stakeholder interviews, adoption metrics, developer experience research.
- Thought leadership contributions (talks, whitepapers, open-source contributions) in ML platform engineering.

## Leadership & Influence
- Acts as platform product owner, balancing user needs, reliability, and compliance.
- Facilitates cross-functional alignment (data, research, product, security) to prioritize platform investments.
- Coaches platform engineers, fosters platform guilds/communities of practice, and drives culture change.
- Presents platform health, adoption metrics, and investment cases to senior leadership.

## References
- `/home/claude/ai-infrastructure-project/research/role-analysis.json` (ML Platform sections)
- `/home/claude/ai-infrastructure-project/research/SKILLS_MATRIX_12_ROLES.md`
- Legacy curriculum repository: `/home/claude/ai-infrastructure-project/repositories/learning/ai-infra-ml-platform-learning/ROLE_REQUIREMENTS.md`
